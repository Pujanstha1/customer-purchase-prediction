{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ea801b-85ee-4980-af6c-d9f70289009d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7edbd015-2594-4994-883e-742ef388c737",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CustomerPurchaseEDA\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d0e0c1c-eadf-4ffc-b414-c6b0fae12ad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/Volumes/workspace/default/project/customer_purchase_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98646e96-d691-4261-a7a9-18c85902f84e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASIC DATA INFORMATION ===\nDataset shape: 1000 rows, 8 columns\nroot\n |-- customer_id: integer (nullable = true)\n |-- order_date: date (nullable = true)\n |-- total_amount: double (nullable = true)\n |-- product_category: string (nullable = true)\n |-- payment_type: string (nullable = true)\n |-- delivery_location: string (nullable = true)\n |-- days_since_last_purchase: integer (nullable = true)\n |-- repeat_purchase_next_30_days: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "print(\"=== BASIC DATA INFORMATION ===\")\n",
    "print(f\"Dataset shape: {df.count()} rows, {len(df.columns)} columns\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4faba0e4-512d-414f-af0f-c10b69d5ef06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== DATA PREVIEW ===\n+-----------+----------+------------+----------------+--------------+-----------------+------------------------+----------------------------+\n|customer_id|order_date|total_amount|product_category|payment_type  |delivery_location|days_since_last_purchase|repeat_purchase_next_30_days|\n+-----------+----------+------------+----------------+--------------+-----------------+------------------------+----------------------------+\n|58         |2023-01-26|37206.75    |Groceries       |Credit Card   |Lalitpur         |26                      |0                           |\n|217        |2023-02-02|1974.96     |Groceries       |Credit Card   |Biratnagar       |154                     |0                           |\n|288        |2023-07-23|35942.97    |Home Appliances |Digital Wallet|Lalitpur         |114                     |1                           |\n|4          |2023-06-13|35057.9     |Clothing        |Bank Transfer |Lalitpur         |55                      |1                           |\n|53         |2023-04-05|19306.4     |Clothing        |Bank Transfer |Biratnagar       |67                      |0                           |\n|236        |2024-07-03|6678.9      |Stationery      |Cash          |Biratnagar       |75                      |1                           |\n|296        |2023-07-16|35376.31    |Electronics     |Credit Card   |Bhaktapur        |20                      |0                           |\n|52         |2024-01-25|14259.69    |Clothing        |Credit Card   |Bhaktapur        |90                      |0                           |\n|137        |2023-03-15|30651.98    |Groceries       |Credit Card   |Lalitpur         |118                     |1                           |\n|139        |2024-07-24|11370.95    |Clothing        |Cash          |Lalitpur         |8                       |1                           |\n+-----------+----------+------------+----------------+--------------+-----------------+------------------------+----------------------------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DATA PREVIEW ===\")\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24693141-94df-4627-b5e2-4a6cef5c3a0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== MISSING VALUES ANALYSIS ===\n+-----------+----------+------------+----------------+------------+-----------------+------------------------+----------------------------+\n|customer_id|order_date|total_amount|product_category|payment_type|delivery_location|days_since_last_purchase|repeat_purchase_next_30_days|\n+-----------+----------+------------+----------------+------------+-----------------+------------------------+----------------------------+\n|          0|         0|           0|               0|           0|                0|                       0|                           0|\n+-----------+----------+------------+----------------+------------+-----------------+------------------------+----------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== MISSING VALUES ANALYSIS ===\")\n",
    "missing_counts = df.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c) for c in df.columns\n",
    "])\n",
    "missing_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "053a6c3c-f4bf-49d5-8f4e-04495c7c667a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== BASIC STATISTICS ===\n+-------+-----------------+------------------+----------------+--------------+-----------------+------------------------+----------------------------+\n|summary|      customer_id|      total_amount|product_category|  payment_type|delivery_location|days_since_last_purchase|repeat_purchase_next_30_days|\n+-------+-----------------+------------------+----------------+--------------+-----------------+------------------------+----------------------------+\n|  count|             1000|              1000|            1000|          1000|             1000|                    1000|                        1000|\n|   mean|          149.671| 25527.73304999998|            NULL|          NULL|             NULL|                  89.439|                       0.532|\n| stddev|88.30700360608944|14172.471314222195|            NULL|          NULL|             NULL|       51.61123907637754|          0.4992246240173108|\n|    min|                1|             508.4|        Clothing| Bank Transfer|        Bhaktapur|                       1|                           0|\n|    max|              300|          49979.95|      Stationery|Digital Wallet|          Pokhara|                     180|                           1|\n+-------+-----------------+------------------+----------------+--------------+-----------------+------------------------+----------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdb07372-5caa-4d24-a992-f88d900c9204",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== TARGET VARIABLE DISTRIBUTION ===\nClass 1: 532 samples\nClass 0: 468 samples\nPositive class rate: 0.532\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TARGET VARIABLE DISTRIBUTION ===\")\n",
    "target_dist = df.groupBy(\"repeat_purchase_next_30_days\").count().collect()\n",
    "for row in target_dist:\n",
    "    print(f\"Class {row[0]}: {row[1]} samples\")\n",
    "\n",
    "\n",
    "\n",
    "class_imbalance = df.agg(\n",
    "    avg(\"repeat_purchase_next_30_days\").alias(\"positive_rate\")\n",
    ").collect()[0][0]\n",
    "\n",
    "print(f\"Positive class rate: {class_imbalance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5a3e64c-5ad0-41a2-a5a0-09c1b1a8f642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== CATEGORICAL FEATURES ANALYSIS ===\nProduct Category Distribution:\n+----------------+-----+------------------+\n|product_category|count|       repeat_rate|\n+----------------+-----+------------------+\n|        Clothing|  223|0.5201793721973094|\n| Home Appliances|  207|0.5217391304347826|\n|       Groceries|  195| 0.517948717948718|\n|      Stationery|  191|0.5759162303664922|\n|     Electronics|  184|0.5271739130434783|\n+----------------+-----+------------------+\n\nPayment Type Distribution:\n+--------------+-----+------------------+\n|  payment_type|count|       repeat_rate|\n+--------------+-----+------------------+\n|   Credit Card|  267|0.5056179775280899|\n| Bank Transfer|  248|0.5524193548387096|\n|          Cash|  246|0.5528455284552846|\n|Digital Wallet|  239|0.5188284518828452|\n+--------------+-----+------------------+\n\nDelivery Location Distribution:\n+-----------------+-----+------------------+\n|delivery_location|count|       repeat_rate|\n+-----------------+-----+------------------+\n|         Lalitpur|  187|0.5775401069518716|\n|       Biratnagar|  170|0.5529411764705883|\n|          Pokhara|  169|0.5088757396449705|\n|        Bhaktapur|  168|0.5297619047619048|\n|           Butwal|  166|0.5240963855421686|\n|        Kathmandu|  140|0.4857142857142857|\n+-----------------+-----+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== CATEGORICAL FEATURES ANALYSIS ===\")\n",
    "\n",
    "# Product category distribution\n",
    "print(\"Product Category Distribution:\")\n",
    "df.groupBy(\"product_category\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"repeat_purchase_next_30_days\").alias(\"repeat_rate\")\n",
    ").orderBy(desc(\"count\")).show()\n",
    "\n",
    "# Payment type analysis\n",
    "print(\"Payment Type Distribution:\")\n",
    "df.groupBy(\"payment_type\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"repeat_purchase_next_30_days\").alias(\"repeat_rate\")\n",
    ").orderBy(desc(\"count\")).show()\n",
    "\n",
    "# Delivery location analysis\n",
    "print(\"Delivery Location Distribution:\")\n",
    "df.groupBy(\"delivery_location\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"repeat_purchase_next_30_days\").alias(\"repeat_rate\")\n",
    ").orderBy(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acfe1658-ebae-4a41-8313-76c0c9bbe9f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== NUMERICAL FEATURES ANALYSIS ===\nTotal Amount by Target Class:\n+----------------------------+------------------+------------------+----------+----------+\n|repeat_purchase_next_30_days|        avg_amount|        std_amount|min_amount|max_amount|\n+----------------------------+------------------+------------------+----------+----------+\n|                           1|25731.204060150405| 14328.61815112422|    674.88|  49922.46|\n|                           0|25296.436944444424|14004.571359429498|     508.4|  49979.95|\n+----------------------------+------------------+------------------+----------+----------+\n\nDays Since Last Purchase by Target Class:\n+----------------------------+-----------------+-----------------+--------+--------+\n|repeat_purchase_next_30_days|         avg_days|         std_days|min_days|max_days|\n+----------------------------+-----------------+-----------------+--------+--------+\n|                           1|89.54323308270676|51.31080299535794|       1|     180|\n|                           0|89.32051282051282|52.00535145986904|       1|     180|\n+----------------------------+-----------------+-----------------+--------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== NUMERICAL FEATURES ANALYSIS ===\")\n",
    "\n",
    "# Total amount statistics by target\n",
    "print(\"Total Amount by Target Class:\")\n",
    "df.groupBy(\"repeat_purchase_next_30_days\").agg(\n",
    "    avg(\"total_amount\").alias(\"avg_amount\"),\n",
    "    stddev(\"total_amount\").alias(\"std_amount\"),\n",
    "    min(\"total_amount\").alias(\"min_amount\"),\n",
    "    max(\"total_amount\").alias(\"max_amount\")\n",
    ").show()\n",
    "\n",
    "# Days since last purchase analysis\n",
    "print(\"Days Since Last Purchase by Target Class:\")\n",
    "df.groupBy(\"repeat_purchase_next_30_days\").agg(\n",
    "    avg(\"days_since_last_purchase\").alias(\"avg_days\"),\n",
    "    stddev(\"days_since_last_purchase\").alias(\"std_days\"),\n",
    "    min(\"days_since_last_purchase\").alias(\"min_days\"),\n",
    "    max(\"days_since_last_purchase\").alias(\"max_days\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca7b0b5-df7e-4814-8a60-b10f2b7a35ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== OUTLIER DETECTION ===\ntotal_amount: Q1=13122.28, Median=25823.45, Q3=37510.09\n  IQR=24387.81, Outliers: 0 (0.0%)\ndays_since_last_purchase: Q1=43.00, Median=89.00, Q3=132.00\n  IQR=89.00, Outliers: 0 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== OUTLIER DETECTION ===\")\n",
    "\n",
    "# Calculate quartiles for numerical columns\n",
    "numerical_cols = [\"total_amount\", \"days_since_last_purchase\"]\n",
    "\n",
    "for col_name in numerical_cols:\n",
    "    quartiles = df.approxQuantile(col_name, [0.25, 0.5, 0.75], 0.0)\n",
    "    q1, median, q3 = quartiles\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    outliers = df.filter((col(col_name) < lower_bound) | (col(col_name) > upper_bound)).count()\n",
    "    print(f\"{col_name}: Q1={q1:.2f}, Median={median:.2f}, Q3={q3:.2f}\")\n",
    "    print(f\"  IQR={iqr:.2f}, Outliers: {outliers} ({outliers/df.count()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f7934b-9bb2-4066-ae8a-8a3257de627d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== TEMPORAL ANALYSIS ===\nOrders by Year:\n+----------+------------+------------------+\n|order_year|total_orders|       repeat_rate|\n+----------+------------+------------------+\n|      2023|         606| 0.533003300330033|\n|      2024|         394|0.5304568527918782|\n+----------+------------+------------------+\n\nOrders by Month:\n+-----------+------------+-------------------+\n|order_month|total_orders|        repeat_rate|\n+-----------+------------+-------------------+\n|          1|         122|0.47540983606557374|\n|          2|         103| 0.5048543689320388|\n|          3|          94| 0.5531914893617021|\n|          4|         106| 0.5566037735849056|\n|          5|          94| 0.5425531914893617|\n|          6|         106| 0.5754716981132075|\n|          7|         122| 0.5081967213114754|\n|          8|          54| 0.6111111111111112|\n|          9|          51| 0.5490196078431373|\n|         10|          49|0.42857142857142855|\n|         11|          56| 0.5178571428571429|\n|         12|          43| 0.6046511627906976|\n+-----------+------------+-------------------+\n\nOrders by Day of Week (1=Sunday):\n+-----------------+------------+------------------+\n|order_day_of_week|total_orders|       repeat_rate|\n+-----------------+------------+------------------+\n|                1|         151|0.5165562913907285|\n|                2|         127|0.5905511811023622|\n|                3|         156|0.5192307692307693|\n|                4|         129|0.4806201550387597|\n|                5|         132|0.5303030303030303|\n|                6|         146| 0.541095890410959|\n|                7|         159|0.5471698113207547|\n+-----------------+------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== TEMPORAL ANALYSIS ===\")\n",
    "\n",
    "# Convert order_date to date type and extract features\n",
    "df_temporal = df.withColumn(\"order_date\", to_date(col(\"order_date\"), \"yyyy-MM-dd\")) \\\n",
    "               .withColumn(\"order_year\", year(\"order_date\")) \\\n",
    "               .withColumn(\"order_month\", month(\"order_date\")) \\\n",
    "               .withColumn(\"order_day_of_week\", dayofweek(\"order_date\"))\n",
    "\n",
    "print(\"Orders by Year:\")\n",
    "df_temporal.groupBy(\"order_year\").agg(\n",
    "    count(\"*\").alias(\"total_orders\"),\n",
    "    avg(\"repeat_purchase_next_30_days\").alias(\"repeat_rate\")\n",
    ").orderBy(\"order_year\").show()\n",
    "\n",
    "print(\"Orders by Month:\")\n",
    "df_temporal.groupBy(\"order_month\").agg(\n",
    "    count(\"*\").alias(\"total_orders\"),\n",
    "    avg(\"repeat_purchase_next_30_days\").alias(\"repeat_rate\")\n",
    ").orderBy(\"order_month\").show()\n",
    "\n",
    "print(\"Orders by Day of Week (1=Sunday):\")\n",
    "df_temporal.groupBy(\"order_day_of_week\").agg(\n",
    "    count(\"*\").alias(\"total_orders\"),\n",
    "    avg(\"repeat_purchase_next_30_days\").alias(\"repeat_rate\")\n",
    ").orderBy(\"order_day_of_week\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8524a270-df11-4814-a3db-ace9aeee8f65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== CORRELATION ANALYSIS ===\nCorrelation Matrix:\n                              total_amount  ...  repeat_purchase_next_30_days\ntotal_amount                      1.000000  ...                      0.015315\ndays_since_last_purchase         -0.013527  ...                      0.002154\nrepeat_purchase_next_30_days      0.015315  ...                      1.000000\n\n[3 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== CORRELATION ANALYSIS ===\")\n",
    "\n",
    "# Convert to Pandas for correlation matrix (small dataset assumption)\n",
    "pandas_df = df.select(\"total_amount\", \"days_since_last_purchase\", \"repeat_purchase_next_30_days\").toPandas()\n",
    "\n",
    "correlation_matrix = pandas_df.corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af4dd6d4-9ec1-433b-bcb4-2d17984102e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== FEATURE INSIGHTS FOR ENGINEERING ===\nCustomer-level Statistics (sample):\n+-----------+------------+------------------+------------------+------------------+------+\n|customer_id|total_orders|   avg_order_value|       total_spent|  avg_days_between|target|\n+-----------+------------+------------------+------------------+------------------+------+\n|         94|           2|         38436.015|          76872.03|              90.5|     0|\n|         29|           6|30403.003333333338|182418.02000000002|51.666666666666664|     0|\n|        284|           8|26746.531250000004|213972.25000000003|            64.875|     1|\n|         88|           5|28865.703999999998|         144328.52|              81.6|     0|\n|        131|           1|          15734.74|          15734.74|              29.0|     1|\n|        148|           4|        19173.3825|          76693.53|              26.5|     1|\n|        279|           6|24256.280000000002|145537.68000000002|122.83333333333333|     0|\n|        195|           1|           7372.58|           7372.58|              37.0|     0|\n|         56|           5|         35757.526|         178787.63|             121.0|     0|\n|        172|           3| 24186.27333333333| 72558.81999999999| 88.33333333333333|     1|\n+-----------+------------+------------------+------------------+------------------+------+\nonly showing top 10 rows\nCustomers with Multiple Orders:\nMulti-order customers: 246/290 (84.8%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== FEATURE INSIGHTS FOR ENGINEERING ===\")\n",
    "\n",
    "# Customer-level aggregations preview\n",
    "customer_stats = df.groupBy(\"customer_id\").agg(\n",
    "    count(\"*\").alias(\"total_orders\"),\n",
    "    avg(\"total_amount\").alias(\"avg_order_value\"),\n",
    "    sum(\"total_amount\").alias(\"total_spent\"),\n",
    "    avg(\"days_since_last_purchase\").alias(\"avg_days_between\"),\n",
    "    first(\"repeat_purchase_next_30_days\").alias(\"target\")\n",
    ")\n",
    "\n",
    "print(\"Customer-level Statistics (sample):\")\n",
    "customer_stats.show(10)\n",
    "\n",
    "print(\"Customers with Multiple Orders:\")\n",
    "multi_order_customers = customer_stats.filter(col(\"total_orders\") > 1).count()\n",
    "total_customers = customer_stats.count()\n",
    "print(f\"Multi-order customers: {multi_order_customers}/{total_customers} ({multi_order_customers/total_customers*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "099d766a-b0ec-4652-a333-cd2a1baa2cbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== DATA QUALITY CHECKS ===\nCustomers with multiple rows: 246\nDate range: 2023-01-01 to 2024-08-03\nNegative amounts: 0\nNegative days since last purchase: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DATA QUALITY CHECKS ===\")\n",
    "\n",
    "# Check for duplicate customer_ids (if this should be unique per row)\n",
    "duplicate_customers = df.groupBy(\"customer_id\").count().filter(col(\"count\") > 1).count()\n",
    "print(f\"Customers with multiple rows: {duplicate_customers}\")\n",
    "\n",
    "# Check date range\n",
    "date_range = df.select(\n",
    "    min(\"order_date\").alias(\"min_date\"),\n",
    "    max(\"order_date\").alias(\"max_date\")\n",
    ").collect()[0]\n",
    "print(f\"Date range: {date_range['min_date']} to {date_range['max_date']}\")\n",
    "\n",
    "# Check for negative values\n",
    "negative_amounts = df.filter(col(\"total_amount\") < 0).count()\n",
    "negative_days = df.filter(col(\"days_since_last_purchase\") < 0).count()\n",
    "print(f\"Negative amounts: {negative_amounts}\")\n",
    "print(f\"Negative days since last purchase: {negative_days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03c242f4-f6fd-4cde-ad86-b2bf439a1507",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== EDA SUMMARY ===\nKey findings for feature engineering:\n1. Check class imbalance in target variable\n2. Identify outliers in total_amount and days_since_last_purchase\n3. Product category and location show different repeat rates\n4. Temporal patterns might be useful features\n5. Customer-level aggregations needed for better features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== EDA SUMMARY ===\")\n",
    "print(\"Key findings for feature engineering:\")\n",
    "print(\"1. Check class imbalance in target variable\")\n",
    "print(\"2. Identify outliers in total_amount and days_since_last_purchase\") \n",
    "print(\"3. Product category and location show different repeat rates\")\n",
    "print(\"4. Temporal patterns might be useful features\")\n",
    "print(\"5. Customer-level aggregations needed for better features\")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "EDA",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}